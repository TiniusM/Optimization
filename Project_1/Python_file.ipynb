{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimisation – Project 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3.2\n",
    "Median problem with weighted Euclidean distance\n",
    "\n",
    "\\begin{equation}\n",
    "\\min_{x \\in \\mathbb{R}} \\sum_{i \\in \\mathcal{M}} v^i d_2(a^i, x)\n",
    "\\end{equation}\n",
    "\n",
    "where $\\mathcal{M} = \\{1, \\dots, m\\}$ and $0 ≤ v^i \\in \\mathbb{R}, \\; \\forall i \\in \\mathcal{M}$.\n",
    "\n",
    "We will here look into the Weiszfeld algorithm for solving the problem above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See overleaf for some of the solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "from autograd import grad\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A solution for implementing an apropriate stopping criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0000000000000002,\n",
       " array([0.08833373, 0.11989191, 0.11138936, 0.12770299, 0.06075476,\n",
       "        0.13134149, 0.16821206, 0.09414424, 0.07888017, 0.01934929]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.random.random(size = (2, 10))\n",
    "x = np.array([0.5, 0.5])\n",
    "v = np.random.rand(10)\n",
    "v = v/np.sum(v)\n",
    "np.sum(v), v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ourWeiszfeld(A, v, epsilon = 10**(-7)):\n",
    "    \"\"\"\n",
    "    A = [a^1,..., a^i,..., a^m]^T   where   a^i = [a_1^i, a_2^i]\n",
    "    Hence, A is a m times 2 matrix\n",
    "    v = [v^1,..., v^i,..., v^m]^T   where   0<v^i \\in \\mathbb{R}, \\forall i \\in \\mathcal{M} \n",
    "    epsilon > 0\n",
    "    \"\"\"\n",
    "    m = A.shape[1]\n",
    "    \n",
    "    #############################\n",
    "    # Test if some positions are optimal\n",
    "    #############################\n",
    "    \n",
    "    # We define a test function to make the code leaner\n",
    "    def testK(k):\n",
    "        sum1 = 0\n",
    "        sum2 = 0\n",
    "        for i in range(m): \n",
    "            if i != k:\n",
    "                dist = np.linalg.norm((A[:, k] - A[:, i])) # d_2(*,*) euclidean distance\n",
    "                sum1 += v[i]* (A[:, k].item(0) - A[:, i].item(0))/(dist)\n",
    "                sum2 += v[i]* (A[:, k].item(1) - A[:, i].item(1))/(dist)\n",
    "                \n",
    "        result = np.sqrt(sum1**2 + sum2**2)\n",
    "        return (result <= v[k])\n",
    "\n",
    "    \n",
    "    for k in range(m): \n",
    "        # theorem 1 test if the theorem is fulfilled for a \"k\"\n",
    "        if testK(k): # do we need to pass the k? should rather not?\n",
    "            x_star = A[:, k] # could just return A[:, k], but this is clearer\n",
    "            return(x_star)\n",
    "    \n",
    "    # choose a starting point x = [x_1, x_2]^T, can be found solving the median problem with ||\\cdot||_2^2\n",
    "    x = np.array([0.463, 0.296])\n",
    "    \n",
    "    \n",
    "    #############################\n",
    "    # Functions for stopping ciretion\n",
    "    #############################\n",
    "    \n",
    "    def sigma(x):\n",
    "        dist = np.linalg.norm(x[:, None] - A, axis = 0)\n",
    "        return np.max(dist)\n",
    "    \n",
    "    def f_d2(x):\n",
    "        return (np.sum(np.multiply(v,np.linalg.norm(x[:, None] - A, axis = 0))))\n",
    "\n",
    "    gradient = grad(f_d2)\n",
    "    \n",
    "    def stoping_criterion(x):\n",
    "        norm_grad = np.linalg.norm(gradient(x))\n",
    "        sig = sigma(x)\n",
    "        return ((norm_grad * sig)/(f_d2(x) - norm_grad * sig))\n",
    "    \n",
    "    k = 0\n",
    "    while stoping_criterion(x) > epsilon and k < 50: # We have k = 50 here just to make the while loop stop\n",
    "        k += 1\n",
    "        # We print the value of the stopping criterion to see what happens\n",
    "        print(stoping_criterion(x))\n",
    "        \n",
    "        for j in range(len(x)):\n",
    "            enum = 0\n",
    "            deno = 0\n",
    "            \n",
    "            for i in range(m):\n",
    "                dist = np.linalg.norm((np.squeeze(np.array(A[:, i])) - x))\n",
    "                enum += v[i]*A[:, i].item(j)/dist\n",
    "                deno += v[i]/dist\n",
    "\n",
    "            x[j] = enum/deno\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def steepestDescent(x_init, obj_func, max_iter = 10000, threshold = 10**(-7)):\n",
    "    \n",
    "    # We create the gradient function for the objective function using autograd\n",
    "    gradient = grad(obj_func)\n",
    "    \n",
    "    # Here we initialize\n",
    "    i = 0\n",
    "    x = np.array(x_init) \n",
    "    rho = 0.4\n",
    "    c = 0.6\n",
    "    diff = np.full((len(x), 1), 100) # initialize some value\n",
    "    while i < max_iter and diff.any() > threshold: # Can use same stopping criterion as above to measure time performance\n",
    "        i += 1\n",
    "        a = 1\n",
    "        grad_k = gradient(x)\n",
    "        # I make a pk for convenience \n",
    "        pk = -grad_k\n",
    "        \n",
    "        # The following is backtracking\n",
    "        while obj_func(x + a*pk) > obj_func(x) + a*c*np.transpose(grad_k) @ pk: # i.e. repeat until not true\n",
    "            a = rho*a\n",
    "        \n",
    "        # The new x is stored\n",
    "        x = x + a*pk\n",
    "        diff = abs(a*pk)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma(x):\n",
    "    dist = np.linalg.norm(x[:, None] - A, axis = 0)\n",
    "    return np.max(dist)\n",
    "    \n",
    "def f_d2(x):\n",
    "    return (np.sum(np.multiply(v,np.linalg.norm(x[:, None] - A, axis = 0))))\n",
    "\n",
    "gradient = grad(f_d2)\n",
    "\n",
    "def stoping_criterion(x):\n",
    "    norm_grad = np.linalg.norm(gradient(x))\n",
    "    sig = sigma(x)\n",
    "    return ((norm_grad * sig)/(f_d2(x) - norm_grad * sig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "steepest_descent_result = steepestDescent(x, f_d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0717655952351659e-11, array([0.59897712, 0.58037236]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoping_criterion(steepest_descent_result), steepest_descent_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.413440381177496\n",
      "0.6291569517484836\n",
      "0.2382598955049261\n",
      "0.11843077136833274\n",
      "0.06657394528706945\n",
      "0.039458161858154546\n",
      "0.023752722588723036\n",
      "0.01435648013790805\n",
      "0.008688274162302298\n",
      "0.0052611927904166545\n",
      "0.0031871360303251622\n",
      "0.0019311747565478035\n",
      "0.001170316163059281\n",
      "0.0007092772368686116\n",
      "0.00042987507572873955\n",
      "0.00026053874472018644\n",
      "0.00015790707633500564\n",
      "9.57036101051107e-05\n",
      "5.800322513949439e-05\n",
      "3.515388471324858e-05\n",
      "2.130553002218571e-05\n",
      "1.2912480819392144e-05\n",
      "7.825746788465751e-06\n",
      "4.7428674897832015e-06\n",
      "2.874455223855166e-06\n",
      "1.7420862521109807e-06\n",
      "1.0558043466222014e-06\n",
      "6.398777689884668e-07\n",
      "3.8780236196362444e-07\n",
      "2.350302583394002e-07\n",
      "1.4244166384505928e-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.59897712, 0.58037234]),\n",
       " array([0.59897712, 0.58037236]),\n",
       " array([[0.37645758, 0.34418904, 0.45974131, 0.82427527, 0.8950342 ,\n",
       "         0.35760366, 0.65227289, 0.88005478, 0.74367886, 0.36362856],\n",
       "        [0.1395243 , 0.42060374, 0.74059467, 0.31761286, 0.82686015,\n",
       "         0.81317752, 0.67095339, 0.09289106, 0.44203628, 0.96070041]]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ourWeiszfeld(A, v), steepest_descent_result, A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From the what we see here, the stopping criterion seem to work as well as the steepest descent algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1, 0, 0],\n",
       "        [0, 0, 1]]), array([0.25, 0.5 , 0.75]))"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A1 = np.array([[1, 0, 0], [0, 0, 1]])\n",
    "v1 = np.array([0.25, 0.5, 0.75])\n",
    "A1, v1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1622776601683795\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import ConvexHull, convex_hull_plot_2d   # get a convex hull computation algorithm\n",
    " \n",
    " \n",
    " \n",
    "#points = np.random.rand(10, 2)   # 30 random points in 2-D\n",
    "#hull = ConvexHull(points)\n",
    " \n",
    "#vecs = []\n",
    "#for i in range(len(hull.vertices)):\n",
    " ##   element = points[hull.vertices[i]]\n",
    " #   element = element.tolist()\n",
    " #   vecs.append(element)\n",
    " \n",
    "def distance(x_1,x_2):\n",
    "    x_1 = np.array(x_1)\n",
    "    x_2 = np.array(x_2)\n",
    "    diff = x_1 - x_2\n",
    "    return np.linalg.norm(diff, 2) \n",
    " \n",
    " \n",
    "def isCounterClockwise(n1,n2, n3):\n",
    "    return ((n1 <n2 <n3) or (n3 < n1 < n2) or (n2 < n3 < n1))\n",
    " \n",
    "def Area(vtxList, n1, n2, n3): # get area of triangle made of point 1,2, 3 from a list of vertices\n",
    "    n = len(vtxList)\n",
    "    vtx1 = vtxList[n1]\n",
    "    vtx2 = vtxList[n2]\n",
    "    vtx3 = vtxList[n3]\n",
    "    # print(vtx1, vtx2, vtx3)\n",
    "    a = distance(vtx1,vtx2)\n",
    "    b = distance(vtx3,vtx2)\n",
    "    c = distance(vtx1,vtx3)\n",
    "    s = (a + b + c) / 2\n",
    "    area = (s*(s-a)*(s-b)*(s-c)) ** 0.5\n",
    "    if isCounterClockwise(n1,n2,n3):\n",
    "        return round(area,3)\n",
    "    else:\n",
    "        return round(-area,3)\n",
    " \n",
    " \n",
    "def GetAllAntiPodalPairs(vtxList):\n",
    "    pairList = []\n",
    "    n = len(vtxList)\n",
    "    i_1 = 1\n",
    "    i_n = 0\n",
    "    i = i_n\n",
    "    j = (i + 1)%n\n",
    "    while (Area(vtxList,i, (i + 1)%n, (j + 1)%n) > Area(vtxList, i, (i + 1)%n, j)):\n",
    "        j = (j + 1)%n\n",
    "        j0 = j\n",
    "    while (j != i_1):\n",
    "        i = (i + 1)%n\n",
    "        pairList.append([i, j])\n",
    "        while ((Area(vtxList, i, (i + 1)%n, (j + 1)%n) > Area(vtxList, i, (i + 1)%n, j))):\n",
    "            j = (j + 1)%n\n",
    "            if (j != i_1):\n",
    "                pairList.append([i, j])\n",
    "        if (Area(vtxList, i, (i + 1)%n, (j + 1)%n) == Area(vtxList, i, (i + 1)%n, j)):\n",
    "            if ((i, j) != (j0, i_n)):\n",
    "                pairList.append([i, (j + 1)%n])\n",
    " \n",
    "    return(pairList)\n",
    " \n",
    " \n",
    " \n",
    "def findDiameter(polygon):\n",
    "    maxx = 0\n",
    "    antiPodalPairs = GetAllAntiPodalPairs(polygon)\n",
    "    for pair in antiPodalPairs:\n",
    "        pairPoint1 = polygon[pair[0]]\n",
    "        pairPoint2 = polygon[pair[1]]\n",
    "        candidate = distance(pairPoint1, pairPoint2)\n",
    "        if (candidate > maxx):\n",
    "            maxx = candidate\n",
    "    return maxx\n",
    " \n",
    " \n",
    "# EXAMPLE\n",
    " \n",
    "polygonZ = [[0,0], [3,0], [2,1], [0,1]]\n",
    "print(findDiameter(polygonZ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare using precision, speed and possibly stability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
